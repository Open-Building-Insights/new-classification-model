{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28789366-105d-4feb-ac1b-1a4d0f721f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ System & Utility Imports\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import argparse\n",
    "import pickle\n",
    "import joblib\n",
    "import fnmatch\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# ✅ Data Handling & Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# ✅ Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ✅ Machine Learning & Model Evaluation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    ")\n",
    "import sklearn.preprocessing as SKP\n",
    "import sklearn.metrics as SKM\n",
    "\n",
    "# ✅ Deep Learning (TensorFlow / Keras)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ✅ Feature Importance (SHAP)\n",
    "import shap\n",
    "\n",
    "# ✅ Geographic Data (if used for spatial analysis)\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# ✅ Logging & Experiment Tracking\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "# ✅ Optimization & Hyperparameter Tuning\n",
    "import optuna\n",
    "\n",
    "# ✅ Math & Statistics\n",
    "from scipy import stats\n",
    "import scipy as SCP\n",
    "\n",
    "# ✅ Progress Bars & Performance Monitoring\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload training dataset (output from 3preprocessing - maybe some cleaning will be needed, dependent on core data)\n",
    "#also we are not using SMOD for training - but in case of potential use in future, I wasn't deleting code related to smod and some other related attributes which were not used in final computation\n",
    "ML_df = pd.read_parquet(r\"all_for_training.parquet\") \n",
    "ML_df.index = [i for i in range(len(ML_df))]\n",
    "ML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3210fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_df = ML_df[ML_df[\"L1_5_class\"].astype(str).str.strip() != \"\"]\n",
    "Counter(ML_df.L1_5_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e0a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_building(row):\n",
    "    \n",
    "    augmented_area = row.area_in_meters * random.uniform(1.001, 1.1)\n",
    "    \n",
    "    if row.SMOD_id == 5:\n",
    "        new_smod = row.SMOD_id + random.randint(0, 1)\n",
    "    else:\n",
    "        new_smod = row.SMOD_id\n",
    "        \n",
    "    augmented_perimeter = row.building_perimeter_in_meters_new * random.uniform(1.001, 1.1)\n",
    "    \n",
    "    perimeter_to_area = augmented_perimeter / augmented_area\n",
    "    \n",
    "    normalized_perimeter_to_area_ratio = perimeter_to_area / 6.5\n",
    "    \n",
    "    augmented_radius_m = row.radius_m * random.uniform(1.001, 1.1)\n",
    "    \n",
    "    augmented_road_density_fixed = row.road_density_fixed * (random.choice([1, row.SMOD_id]) * 1.01)\n",
    "    augmented_building_density_100 = row.building_density_100 * (random.choice([1, row.SMOD_id]) * 1.01)\n",
    "    augmented_nearest_city_distance_km = row.nearest_city_distance_km * random.uniform(0.9, 1)\n",
    "    \n",
    "    augmented_row = {\n",
    "        'area_in_meters': augmented_area,\n",
    "        'SMOD_id': new_smod,\n",
    "        'building_perimeter_in_meters_new': augmented_perimeter,\n",
    "        'perimeter_to_area': perimeter_to_area,\n",
    "        'radius_m': augmented_radius_m,\n",
    "        'normalized_perimeter_to_area_ratio': normalized_perimeter_to_area_ratio,\n",
    "        'road_density_fixed': augmented_road_density_fixed,\n",
    "        'building_density_100': augmented_building_density_100,\n",
    "        'nearest_city_distance_km': augmented_nearest_city_distance_km,\n",
    "    }\n",
    "    \n",
    "    return augmented_row\n",
    "\n",
    "def augment_df(df):\n",
    "    \n",
    "    df.index = [i for i in range(len(df))]\n",
    "    for row in df.itertuples():\n",
    "        \n",
    "        augmented_row = augment_building(row)\n",
    "        \n",
    "        for col_name, value in augmented_row.items():\n",
    "            \n",
    "            df.at[row.Index, col_name] = value\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0372574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_df = pd.concat([ML_df_residential_above_1500, reduced_df, ML_df_residential_above_200, augmented_df, ML_df_nonresidential, ML_df_industrial])\n",
    "ML_df = ML_df[(ML_df.use_for_training == 'Yes')]\n",
    "Counter(ML_df.L1_5_class)\n",
    "ML_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(idx):\n",
    "#     parts = [0, int(data_len * 0.8), int(data_len * 0.9), data_len]\n",
    "    \n",
    "    if str(idx)[-1] in ['0', '1', '2', '6', '7', '8', '9']:\n",
    "        return 'train'\n",
    "    elif str(idx)[-1] in ['3', '4']:\n",
    "        return 'validation'\n",
    "    elif str(idx)[-1] in ['5']:\n",
    "        return 'test'\n",
    "\n",
    "data_len = len(ML_df)\n",
    "ML_df['index_column'] = [i for i in range(len(ML_df))]\n",
    "ML_df['image_ML_type'] = [\"initval\" for _ in range(len(ML_df))]\n",
    "\n",
    "for ml_class in list(set(ML_df['L1_5_class'])):\n",
    "    \n",
    "    \n",
    "    ML_df = ML_df.sort_values('area_in_meters', ascending=True)\n",
    "    ml_class_data_idxs = ML_df[ML_df['L1_5_class'] == ml_class].index.tolist()\n",
    "    for row_idx, df_idx in enumerate(ml_class_data_idxs):\n",
    "        \n",
    "        ML_df.at[df_idx, 'image_ML_type'] = assign_label(row_idx)\n",
    "        \n",
    "split_result = ML_df[['image_ML_type', 'L1_5_class', 'index_column']].groupby(['image_ML_type', 'L1_5_class']).count()\n",
    "split_result['split in %'] = round(100 * split_result['index_column'] / data_len, 3)\n",
    "print(split_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9707f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ML_df[['image_ML_type', 'L1_5_class']].groupby(['image_ML_type', 'L1_5_class']).agg({'L1_5_class': ['count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09b122-4c9b-4f53-9bd7-a423774fed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gML = ML_df[['image_ML_type', 'L1_5_class']].reset_index().groupby(['image_ML_type', 'L1_5_class'])[\"L1_5_class\"].count().reset_index(name=\"count\")\n",
    "gML = pd.DataFrame(gML)\n",
    "gML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44670d6-c3d4-4f84-adb7-b3e88f9dd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "models_dir = os.path.join(base_path, \"models\") \n",
    "checkpoints_and_metadata = os.path.join(base_path, \"model_checkpoints_and_metadata\") \n",
    "artifact_dir = os.path.join(base_path, \"mlruns\") \n",
    "my_artifacts = os.path.join(base_path, \"artifacts\")\n",
    "\n",
    "# Delete old directories (but NOT `mlruns/` since MLflow manages it)\n",
    "try:\n",
    "    shutil.rmtree(models_dir)\n",
    "    shutil.rmtree(checkpoints_and_metadata)\n",
    "    shutil.rmtree(my_artifacts)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    pass  \n",
    "\n",
    "# Recreate necessary directories\n",
    "os.makedirs(checkpoints_and_metadata, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(my_artifacts, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f252700-bb7a-45f8-a2c0-b3be87578f50",
   "metadata": {},
   "source": [
    "## Creating test train val datasets - or load the previously saved one as the pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b1e802-bd19-45cb-8dd8-041d514c80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_number = {\n",
    "    'nonresidential': 0,\n",
    "    'residential': 1,\n",
    "    'industrial':2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68d342bd-ddcf-47fc-ae85-0da1693bc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_area = 20_000\n",
    "#normalize_height = 20\n",
    "#normalize_smod = 6 \n",
    "normalize_int_t=3300\n",
    "normalize_int_distance=180\n",
    "#avg_range_k5_capped=1100\n",
    "normalize_road_count=30\n",
    "normalize_road_density=5000\n",
    "normalize_perim_to_area=7\n",
    "#normalize_nearest_city=400\n",
    "normalize_road_distance=10100\n",
    "normalize_radius=100\n",
    "#Anormalize_height_mean=13\n",
    "#normalize_density_100=110\n",
    "#normalize_density_500=1900\n",
    "normalize_density_100=200\n",
    "#normalize_perimeter = 500\n",
    "\n",
    "\n",
    "#normalize_int_t=4691\n",
    "#normalize_ranges_k5=2351\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59cf3ad7-8ba8-4ed1-ad39-8fb48c5dfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset storage for numeric features\n",
    "\n",
    "folders_tree = {\n",
    "    'train': ['nonresidential', 'residential','industrial'],\n",
    "    'test': ['nonresidential', 'residential','industrial'],\n",
    "    'validation': ['nonresidential', 'residential','industrial'],\n",
    "}\n",
    "\n",
    "train_numeric, train_labels = [], []\n",
    "validation_numeric, validation_labels = [], []\n",
    "test_numeric, test_labels = [], []\n",
    "\n",
    "# Function to extract only numerical features and label\n",
    "def create_learning_sample(row):\n",
    "    output = get_class_number[row.L1_5_class]  # Just return the class index (0, 1, or 2)\n",
    "    numeric_features = [\n",
    "        #feature 0\n",
    "        row.area_in_meters / normalize_area, \n",
    "        #feature 1\n",
    "        #row.SMOD_id / normalize_smod,\n",
    "        #feature 2\n",
    "        row.normalized_perimeter_to_area_ratio,\n",
    "        #feature 3\n",
    "        row.radius_m/normalize_radius,\n",
    "        #feature 4\n",
    "        row.distance_to_1/5000,\n",
    "        #feature 5\n",
    "        row.distance_to_2/4000,\n",
    "        #feature 6\n",
    "        row.distance_to_3/3000,\n",
    "        #feature 7\n",
    "        row.distance_to_4/2000,\n",
    "        #feature 8\n",
    "        row.road_density_for_4_fixed/60_000,\n",
    "        #feature 9\n",
    "        row.road_density_for_5_fixed/75_000,\n",
    "        #feature 10\n",
    "        row.building_density_100/normalize_density_100,\n",
    "        #feature 11\n",
    "        #row.building_perimeter_in_meters_new/normalize_perimeter\n",
    "         # row.internet_towers_nearby_capped/normalize_int_t,\n",
    "        #row.nearest_internet_tower_distance_km_capped/normalize_int_distance,\n",
    "        # row.avg_range_k_nearest_with_5/avg_range_k5_capped,\n",
    "        # row.road_density_fixed/normalize_road_density,\n",
    "        # row.roads_nearby_fixed/normalize_road_count,\n",
    "        # row.nearest_city_distance_km/normalize_nearest_city,\n",
    "        #row.height_mean_cappedNEW/normalize_height_mean,\n",
    "\n",
    "    ]\n",
    "    return numeric_features, output\n",
    "\n",
    "\n",
    "for type_folder, class_folders in folders_tree.items():\n",
    "        \n",
    "    for classfolder in class_folders:\n",
    "        \n",
    "        class_data = ML_df[(ML_df.image_ML_type == type_folder) & (ML_df.L1_5_class == classfolder)]\n",
    "        \n",
    "        for _, row in class_data.iterrows():  \n",
    "            \n",
    "            numeric_features, output = create_learning_sample(row)\n",
    "            \n",
    "            if type_folder == \"train\":\n",
    "                train_numeric.append(numeric_features)\n",
    "                train_labels.append(output)\n",
    "                \n",
    "            elif type_folder == \"validation\":\n",
    "                validation_numeric.append(numeric_features)\n",
    "                validation_labels.append(output)\n",
    "                \n",
    "            elif type_folder == \"test\":\n",
    "                test_numeric.append(numeric_features)\n",
    "                test_labels.append(output)\n",
    "                \n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "train_numeric = np.array(train_numeric)\n",
    "train_labels = np.array(train_labels)\n",
    "validation_numeric = np.array(validation_numeric)\n",
    "validation_labels = np.array(validation_labels)\n",
    "test_numeric = np.array(test_numeric)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Convert integer labels (0, 1, 2) to one-hot\n",
    "train_labels = to_categorical(train_labels, num_classes=3)\n",
    "validation_labels = to_categorical(validation_labels, num_classes=3)\n",
    "test_labels = to_categorical(test_labels, num_classes=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57c5fb-b231-4e9b-b64c-7387ee819de1",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/700709927831304081', creation_time=1753082545835, experiment_id='700709927831304081', last_update_time=1753082545835, lifecycle_stage='active', name='Experiment NN 1 kenya', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Ensure experiment exists before setting it\n",
    "# mlflow ui - in terminal in case it is loading too long or crashing\n",
    "experiment_name = \"Experiment 1\"\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "except mlflow.exceptions.MlflowException:\n",
    "    \n",
    "    experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id  # If already exists, get it\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80eca3a-e334-429c-b935-c720ca69b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"Run_Numerical_Model_NN_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_AllInputs_LastDatasetVersion_3categories\"\n",
    "\n",
    "class LogLearningCurvesCallback(keras.callbacks.Callback):\n",
    "        def on_train_end(self, logs=None):\n",
    "            \"\"\"Called at the end of training to log learning curves.\"\"\"\n",
    "            plt.figure(figsize=(16, 16))\n",
    "    \n",
    "            metrics = [\"accuracy\", \"loss\", 'prc']\n",
    "            titles = [\"Training and Validation Accuracy\", \"Training and Validation Loss\", \"Training and Validation AUC-Prec-Recall\"]\n",
    "            \n",
    "            for i, metric in enumerate(metrics):\n",
    "                plt.subplot(3, 1, i + 1)\n",
    "    \n",
    "                epochs = range(1, len(self.model.history.history[metric]) + 1)\n",
    "    \n",
    "                plt.plot(epochs, self.model.history.history[metric], label=f'Training {metric}')\n",
    "                plt.plot(epochs, self.model.history.history[f'val_{metric}'], label=f'Validation {metric}')\n",
    "                \n",
    "                plt.legend(loc='lower right')\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(metric.capitalize())\n",
    "                plt.xticks(epochs)  \n",
    "                plt.title(titles[i])\n",
    "    \n",
    "            learning_curve_path = os.path.join(\"artifacts\", \"learning_curves\", \"learning_curve.png\")\n",
    "            os.makedirs(os.path.dirname(learning_curve_path), exist_ok=True)\n",
    "    \n",
    "            plt.savefig(learning_curve_path)\n",
    "            plt.close()\n",
    "    \n",
    "            mlflow.log_artifact(learning_curve_path, artifact_path=\"learning_curves\")\n",
    "\n",
    "class LogMetricsPerEpochCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "\n",
    "        for metric_name, metric_value in logs.items():\n",
    "            if metric_value is not None:\n",
    "                mlflow.log_metric(metric_name, float(metric_value), step=epoch+1)\n",
    "\n",
    "            precision_train = logs.get(\"precision\", 0)\n",
    "            recall_train = logs.get(\"recall\", 0)\n",
    "            f1_train = (2 * precision_train * recall_train) / (precision_train + recall_train) if (precision_train + recall_train) != 0 else 0\n",
    "            mlflow.log_metric(\"f1\", f1_train, step=epoch + 1)\n",
    "\n",
    "            precision_val = logs.get(\"val_precision\", 0)\n",
    "            recall_val = logs.get(\"val_recall\", 0)\n",
    "            f1_val = (2 * precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) != 0 else 0\n",
    "            mlflow.log_metric(\"f1_val\", f1_val, step=epoch + 1)\n",
    "\n",
    "        print(f\"✅ MLflow Metrics Logged for Epoch {epoch}: {logs.keys()}\")  \n",
    "\n",
    "class MemoryUsageCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        memory_usage = round(psutil.Process(os.getpid()).memory_info().rss / (1024**3), 3)\n",
    "        print(f\"Memory usage on epoch {epoch} start: {memory_usage} GB\")\n",
    "        mlflow.log_metric(\"memory_usage_start\", memory_usage, step=epoch+1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        memory_usage = round(psutil.Process(os.getpid()).memory_info().rss / (1024**3), 3)\n",
    "        print(f\"Memory usage on epoch {epoch} end: {memory_usage} GB\")\n",
    "        mlflow.log_metric(\"memory_usage_end\", memory_usage, step=epoch+1)\n",
    "\n",
    "class ClearMemory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        collected = gc.collect()\n",
    "        print(f\"Epoch {epoch}: garbage collector collected {collected} objects.\")\n",
    "        mlflow.log_metric(\"gc_collected_objects\", collected, step=epoch+1)\n",
    "        \n",
    "# Define Neural Network\n",
    "def build_model():\n",
    "    numeric_input = Input(shape=(train_numeric.shape[1], ), name=\"numeric_input\")\n",
    "    x = Dense(100, activation='relu')(numeric_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64,activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(8, activation= 'relu')(x)\n",
    "    x = Dense(4, activation='relu')(x)\n",
    "    output = Dense(3, activation='softmax')(x)  \n",
    "\n",
    "    model = Model(inputs=numeric_input, outputs=output)\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001), \n",
    "        loss='categorical_crossentropy',  \n",
    "        metrics=[\n",
    "            CategoricalAccuracy(name=\"accuracy\"),  \n",
    "            Precision(name=\"precision\"),  \n",
    "            Recall(name=\"recall\"),  \n",
    "            AUC(name=\"auc\"), \n",
    "            AUC(name=\"prc\", curve=\"PR\")])  \n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize Model\n",
    "model = build_model()\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # Log Model Parameters\n",
    "    #mlflow.log_params({'num_layers': 3, 'units': 416, 'activation': 'tanh', 'dropout': 0.18377584830628102, 'learning_rate': 0.0013730588254974561, 'optimizer': 'RMSprop', 'batch_size': 32, 'reduce_lr_factor': 0.13072282886518677})\n",
    "\n",
    "    # Train Model\n",
    "    # early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "    reduce_learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=1, verbose=1, min_delta=0.0005, min_lr=1e-14)\n",
    "\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_numeric, train_labels, \n",
    "        epochs=25, batch_size=32, \n",
    "        validation_data=(validation_numeric, validation_labels),\n",
    "        callbacks=[reduce_learning_rate,\n",
    "        # early_stopping,\n",
    "        LogMetricsPerEpochCallback(),\n",
    "        LogLearningCurvesCallback(),  \n",
    "        MemoryUsageCallback(),         \n",
    "        ClearMemory()])                 \n",
    "\n",
    "    y_train_pred = np.argmax(model.predict(train_numeric), axis=1)\n",
    "    y_val_pred = np.argmax(model.predict(validation_numeric), axis=1)\n",
    "    y_train_pred_proba = model.predict(train_numeric)\n",
    "    y_val_pred_proba = model.predict(validation_numeric)\n",
    "\n",
    "    # Convert true labels from one-hot to integer format\n",
    "    train_labels = np.argmax(train_labels, axis=1)  \n",
    "    validation_labels = np.argmax(validation_labels, axis=1)\n",
    "    test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(train_labels, y_train_pred),\n",
    "        \"val_accuracy\": accuracy_score(validation_labels, y_val_pred),\n",
    "        \"precision\": precision_score(train_labels, y_train_pred, average=\"macro\"),\n",
    "        \"val_precision\": precision_score(validation_labels, y_val_pred, average=\"macro\"),\n",
    "        \"recall\": recall_score(train_labels, y_train_pred, average=\"macro\"),\n",
    "        \"val_recall\": recall_score(validation_labels, y_val_pred, average=\"macro\"),\n",
    "        \"f1\": f1_score(train_labels, y_train_pred, average=\"macro\"),\n",
    "        \"f1_val\": f1_score(validation_labels, y_val_pred, average=\"macro\"),\n",
    "        # \"auc\": roc_auc_score(train_labels, y_train_pred_proba, multi_class=\"ovo\"),\n",
    "        # \"val_auc\": roc_auc_score(validation_labels, y_val_pred_proba, multi_class=\"ovo\"),\n",
    "        # \"prc\": average_precision_score(train_labels, y_train_pred_proba, average=\"macro\"),\n",
    "        # \"val_prc\": average_precision_score(validation_labels, y_val_pred_proba, average=\"macro\"),\n",
    "        \"loss\": history.history['loss'][-1],  \n",
    "        \"val_loss\": history.history['val_loss'][-1]  \n",
    "    }\n",
    "\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        mlflow.log_metric(metric_name, metric_value, step=0)\n",
    "\n",
    "    # Save Model\n",
    "    model_save_path = os.path.join(\"models\", \"neural_network_3cat.h5\")\n",
    "    model.save(model_save_path)\n",
    "    mlflow.log_artifact(model_save_path, artifact_path=\"models\")\n",
    "\n",
    "    model_save_path = os.path.join(\"models\", \"neural_network_3cat.keras\")\n",
    "    model.save(model_save_path)\n",
    "    mlflow.log_artifact(model_save_path, artifact_path=\"models\")\n",
    "\n",
    "\n",
    "    def log_confusion_matrix(y_true, y_pred, filename, title):\n",
    "        cf_mtx = confusion_matrix(y_true, y_pred)\n",
    "        class_labels = ['nonresidential', 'residential', 'industrial']\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.heatmap(cf_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(title)\n",
    "\n",
    "        cm_path = os.path.join(\"artifacts\", filename)\n",
    "        os.makedirs(os.path.dirname(cm_path), exist_ok=True)\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(cm_path, artifact_path=\"confusion_matrices\")\n",
    "\n",
    "    log_confusion_matrix(validation_labels, y_val_pred, \"nn_3cat_confusion_matrix.png\", \"Confusion Matrix - NN Model\")\n",
    "\n",
    "    feature_names = [\"area_in_meters\", \"normalized_perimeter_to_area_ratio\", \"radius_m\", \"distance_to_1\", \"distance_to_2\", \"distance_to_3\",\"distance_to_4\", \"road_density_for_4_fixed\", 'road_density_for_5_fixed', 'building_density_100' ]\n",
    "\n",
    "    def log_shap_feature_importance(feature_names):\n",
    "        explainer = shap.Explainer(model, train_numeric)\n",
    "        shap_values = explainer(train_numeric[:100])  # Sample subset\n",
    "\n",
    "        shap.summary_plot(\n",
    "            shap_values, \n",
    "            features=validation_numeric[:100], \n",
    "            feature_names=feature_names,  # Pass feature names here\n",
    "            show=False\n",
    "        )\n",
    "\n",
    "        feature_importance_path = os.path.join(\"artifacts\", \"nn_shap_feature_importance.png\")\n",
    "        os.makedirs(os.path.dirname(feature_importance_path), exist_ok=True)\n",
    "        plt.savefig(feature_importance_path)\n",
    "        plt.close()\n",
    "\n",
    "        mlflow.log_artifact(feature_importance_path, artifact_path=\"feature_importance\")\n",
    "\n",
    "    # Example usage:\n",
    "    log_shap_feature_importance(feature_names) \n",
    "\n",
    "    # Test Set Predictions\n",
    "    y_test_pred = np.argmax(model.predict(test_numeric), axis=1)\n",
    "    y_test_pred_proba = model.predict(test_numeric)\n",
    "\n",
    "    test_metrics = {\n",
    "        'test_accuracy': accuracy_score(test_labels, y_test_pred),\n",
    "        'test_precision': precision_score(test_labels, y_test_pred, average=\"macro\"),\n",
    "        'test_recall': recall_score(test_labels, y_test_pred, average=\"macro\"),\n",
    "        'test_f1': f1_score(test_labels, y_test_pred, average=\"macro\"),\n",
    "        'test_auc': roc_auc_score(test_labels, y_test_pred_proba, multi_class=\"ovo\")\n",
    "    }\n",
    "\n",
    "    for metric_name, metric_value in test_metrics.items():\n",
    "        mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "    log_confusion_matrix(test_labels, y_test_pred, \"nn_3cat_confusion_matrix_TEST.png\", \"Confusion Matrix TEST - NN Model\")    \n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "print(\"Training complete. Metrics, model, and confusion matrix logged in MLflow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e1387-5acf-4377-ad30-774d2ee54082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "loss = history.history[\"loss\"]\n",
    "epochs = range(0,25)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label = \"Validation loss\")\n",
    "plt.plot(epochs, loss, \"g--\",\n",
    "         label = \"Training loss\")\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d2c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a305916",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_area = 20_000\n",
    "#normalize_height = 20\n",
    "normalize_smod = 6 \n",
    "normalize_int_t=3300\n",
    "normalize_int_distance=180\n",
    "#avg_range_k5_capped=1100\n",
    "normalize_road_count=30\n",
    "normalize_road_density=5000\n",
    "normalize_perim_to_area=7\n",
    "#normalize_nearest_city=400\n",
    "normalize_road_distance=10100\n",
    "normalize_radius=100\n",
    "#Anormalize_height_mean=13\n",
    "#normalize_density_100=110\n",
    "#normalize_density_500=1900\n",
    "normalize_density_100=200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload dataset with real data for validation\n",
    "df_real_data = pd.read_parquet(r\"all_for_validation.parquet\")\n",
    "df_real_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aad6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data shape: (400, 41)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_real_data['area_in_meters'] = df_real_data['area_in_meters'] / normalize_area\n",
    "#df_real_data['SMOD_id'] = df_real_data['SMOD_id'] / normalize_smod\n",
    "df_real_data['normalized_perimeter_to_area_ratio']\n",
    "df_real_data['radius_m'] = df_real_data['radius_m'] / normalize_radius\n",
    "df_real_data['distance_to_1'] = df_real_data['distance_to_1'] / 5000\n",
    "df_real_data['distance_to_2'] = df_real_data['distance_to_2'] / 4000\n",
    "df_real_data['distance_to_3'] = df_real_data['distance_to_3'] / 3000\n",
    "df_real_data['distance_to_4'] = df_real_data['distance_to_4'] / 2000\n",
    "df_real_data['road_density_for_4_fixed'] = df_real_data['road_density_for_4_fixed'] / 60_000\n",
    "df_real_data['road_density_for_5_fixed'] = df_real_data['road_density_for_5_fixed'] / 75_000\n",
    "df_real_data['building_density_100'] = df_real_data['building_density_100'] / normalize_density_100\n",
    "#df_real_data['building_perimeter_in_meters_new'] = df_real_data['building_perimeter_in_meters_new']/500\n",
    "\n",
    "print(\"Real data shape:\", df_real_data.shape)\n",
    "df_real_data.columns\n",
    "\n",
    "df_real_dropped = df_real_data.drop(columns=['id', 'latitude', 'longitude', 'vida_confidence',\n",
    "       'osm_type', 'geometry', 'trusted_source', 'building_tag',\n",
    "       'use_for_training', 'L1_class', 'L1_5_class', 'L2_class', 'SMOD_name',\n",
    "       'SMOD_id', 'image_source_bytes', 'image_ML_type', 'perimeter_in_meters',\n",
    "       'building_perimeter_in_meters_new', 'perimeter_to_area_ratio', 'centroid', \n",
    "       'num_vertices', 'centroid_x', 'centroid_y', 'nearest_road_type_1',\n",
    "       'nearest_road_type_2', \n",
    "       'nearest_road_type_3',  'nearest_road_type_4',\n",
    "       'building_density_50', 'building_density_250',\n",
    "       'building_density_500', 'del'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #feature 1\n",
    "\n",
    "        #feature 2\n",
    "        #row.normalized_perimeter_to_area_ratio,\n",
    "        # row.internet_towers_nearby_capped/normalize_int_t,\n",
    "        #row.nearest_internet_tower_distance_km_capped/normalize_int_distance,\n",
    "        # row.avg_range_k_nearest_with_5/avg_range_k5_capped,\n",
    "        #feature 3\n",
    "        # row.road_density_fixed/normalize_road_density,\n",
    "        #feature 4\n",
    "\n",
    "\n",
    "        # row.roads_nearby_fixed/normalize_road_count,\n",
    "        # row.nearest_city_distance_km/normalize_nearest_city,\n",
    "        #row.height_mean_cappedNEW/normalize_height_mean,\n",
    "        #feature 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d9aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data shape: (400, 10)\n",
      "Model input shape: (None, 10)\n"
     ]
    }
   ],
   "source": [
    "df_real_dropped.columns\n",
    "\n",
    "\n",
    "print(\"Real data shape:\", df_real_dropped.shape)\n",
    "print(\"Model input shape:\", model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de269682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model URI: runs:/e286f510addc471f945ae11a0ab1da0c/models/neural_network_3cat.keras\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"Experiment 1\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Get the latest run\n",
    "latest_run = mlflow.search_runs(experiment_ids=[experiment.experiment_id], order_by=[\"start_time desc\"]).iloc[0]\n",
    "\n",
    "# Get the model URI for the latest run\n",
    "run_id = latest_run.run_id\n",
    "model_uri = f\"runs:/{run_id}/models/neural_network_3cat.keras\"\n",
    "print(f\"Model URI: {model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e369b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#local_model_path = \"neural_network_3cat.keras\"\n",
    "#model = mlflow.keras.load_model(local_model_path)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "predictions = model.predict(df_real_dropped)\n",
    "\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "class_labels = ['Non-Residential', 'Residential', 'Industrial']\n",
    "predicted_labels = [class_labels[i] for i in predicted_classes]\n",
    "\n",
    "for i, label in enumerate(predicted_labels):\n",
    "    print(f\"Instance {i}: Predicted Label: {label}\")\n",
    "\n",
    "\n",
    "import json\n",
    "predictions_path = \"artifacts/predictions.csv\"\n",
    "with open(predictions_path, \"w\") as f:\n",
    "    json.dump(predicted_labels, f)\n",
    "\n",
    "mlflow.log_artifact(predictions_path, artifact_path=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d27b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_data[\"prediction\"] = predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload validation dataset for merge with prediction\n",
    "df_real_class = pd.read_parquet(r\"all_for_validation.parquet\")\n",
    "df_real_class.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_class[\"id\"]\n",
    "df_real_class = df_real_class[[\"id\", \"L1_5_class\"]]\n",
    "df_real_class\n",
    "df_real_data = df_real_data.merge(df_real_class[[\"id\", \"L1_5_class\"]], on=\"id\", how=\"left\")\n",
    "df_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_data.to_csv(\"to_compare_v1.csv\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage: 326/400 = 81.50%\n",
      "True: 326\n",
      "False residential without mixed use: 74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'Residential': 211, 'Non-Residential': 135, 'Industrial': 54})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some quick analysis\n",
    "\n",
    "df_real_data[\"prediction_normalized\"] = (\n",
    "    df_real_data[\"prediction\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "df_real_data[\"L1_5_class_y_normalized\"] = (\n",
    "    df_real_data[\"L1_5_class_y\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "df_real_data[\"match\"] = (\n",
    "    df_real_data[\"prediction_normalized\"] == df_real_data[\"L1_5_class_y_normalized\"]\n",
    ")\n",
    "df_real_data\n",
    "\n",
    "true_count = (df_real_data[\"match\"] == True).sum()\n",
    "false_count = (df_real_data[\"match\"] == False).sum()\n",
    "\n",
    "print(f\"Percentage: {true_count}/400 = {true_count / 400:.2%}\")\n",
    "print(f\"True: {true_count}\")\n",
    "print(f\"False residential without mixed use: {false_count}\")\n",
    "Counter(df_real_data.prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
